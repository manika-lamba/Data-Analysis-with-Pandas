{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with Pandas ‚Äî¬†Day 3\n",
    "## Text Manipulation, Functions, Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Day 3 notebook for the June 2021 course \"Data Analysis with Pandas,\" part of the [Text Analysis Pedagogy Institute](https://nkelber.github.io/tapi2021/book/intro.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we will cover:\n",
    "\n",
    "* String Methods / Text Manipulation\n",
    "* Applying Functions\n",
    "* Converting Between Data Types\n",
    "* Working with Time Series Data\n",
    "\n",
    "___\n",
    "\n",
    "## Dataset\n",
    "### Seattle Public Library Book Circulation Data\n",
    "\n",
    "This week, we will be working with [circulation data](https://data.seattle.gov/Community/Checkouts-by-Title/tmmm-ytt6) made publicly avilable by the Seattle Public Library. The dataset includes items that were checked out 20+ times in a month between January 2015 and June 2021.\n",
    "\n",
    "For more information about this dataset, see the Seattle Public Library's [data portal](https://data.seattle.gov/Community/Checkouts-by-Title/tmmm-ytt6).\n",
    "___\n",
    "\n",
    "## Import Pandas\n",
    "\n",
    "To use the Pandas library, we first need to `import` it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Pandas will display 60 rows and 20 columns. I often change [Pandas' default display settings](https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html) to show more rows or columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read in a CSV file, we will use the function `pd.read_csv()` and insert the name of our desired file path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df = pd.read_csv('Seattle-Library_2015-2021.csv', delimiter=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lingering Issues with SPL Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've learned a lot about Pandas so far, and we've learned a lot about our Seattle Public Library data, too. Let's take a moment to appreciate how far we've come:\n",
    "\n",
    "We've been able to get a broad overview of our data, subset our data in different ways, make simple plots, and even figure out the books and material types that were checked out most between 2015-2021. That's pretty awesome!\n",
    "\n",
    "<img src=\"https://images-na.ssl-images-amazon.com/images/I/41txHpdA8QL.jpg\" width=250/>\n",
    "\n",
    "\n",
    "But unfortunately there are still some lingering problems and issues with our data.\n",
    "\n",
    "For example, the titles in the dataset are sometimes recorded inconsistently and have slightly different versions. If we calculate the total checkouts for each title, we can see that Sue Grafton's *A\" is for Alibi: Kinsey Millhone Series, Book 1* shows up multiple times in different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df.groupby('Title')[['Checkouts']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other small inconsistencies in the data, too, such as trailing commas in the \"Publishers\" column, which make it more difficult for us to get a true sense of publishing trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Publisher'].value_counts()[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Penguin_Random_House.svg/1200px-Penguin_Random_House.svg.png\" width=250/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, when we try to filter for a particular title, like Elena Ferrante's *My Brilliant Friend*, we have to know the full and complete title for our filtering method to work (pssst can you tell that I'm obsessed with Elena Ferrante yet...?) \n",
    "\n",
    "Here's what happens when we filter the DataFrame for just \"My Brilliant Friend\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean vector\n",
    "title_filter = seattle_df['Title'] == 'My Brilliant Friend'\n",
    "\n",
    "# Filter\n",
    "seattle_df[title_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing. No dice. üé≤\n",
    "\n",
    "Using this filter method, we have to specify the entire title to get what we're looking for, which is challenging and annoying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean vector\n",
    "title_filter = seattle_df['Title'] == 'My Brilliant Friend: Neapolitan Series, Book 1'\n",
    "\n",
    "# Filter\n",
    "seattle_df[title_filter].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, our \"Subjects\" column still includes multiple subjects in manys rows, so we don't know very much about overall \"Subject\" trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Subjects']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus we still don't have any datetime information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['CheckoutYear'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But don't fret. We're going to resolve all of these lingering issues in this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clean up many of the inconsistencies in our data by using Pandas string methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition pythonreview\" name=\"html-admonition\" style=\"background: lightgreen; padding: 10px\">\n",
    "<p class=\"title\"><b/>Python Review üêç </b></p>\n",
    "\n",
    "The Python data type for textual data is a \"string.\" Strings are denoted by single or double quotation marks.\n",
    "\n",
    "| Data Type       | Explanation          | Example  |\n",
    "| ------------- |:-------------:| -----:|\n",
    "| String     | Text | ```\"brilliant\", '40'``` |\n",
    "| Integer     | Whole Numbers      |   ```40``` |\n",
    "| Float | Decimal Numbers      |   ```40.2``` |\n",
    "| Boolean | True/False     |   ```False``` |\n",
    "\n",
    "There are a number of convenient, built-in Python methods that allow you to manipulate and work with strings, such as stripping leading and trailing whitespace or replacing certain characters.\n",
    "\n",
    "| **String Method** | **Explanation**                                                                                   |\n",
    "|:-------------:|:---------------------------------------------------------------------------------------------------:|\n",
    "| `string.lower()`         | makes the string lowercase                                                   \n",
    "| `string.strip()`         | removes lead and trailing white spaces     |\n",
    "| `string.replace('old string', 'new string')`      | replaces `old string` with `new string`          |\n",
    "| `string.split('delim')`          | returns a list of substrings separated by the given delimiter |\n",
    "\n",
    "                                                            \n",
    "</div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assign the string \"?My Brilliant Friend?\" to the variable `sample_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_string = \"?My Brilliant Friend?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we check its data type, we can see that it is indeed a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sample_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can strip leading and trailing characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_string.strip('?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can make the entire string uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_string.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, Pandas has special [Pandas string methods](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#string-methods), too. Many of them are very similar to Python string methods, except they will transform every single string value in a column, and we need to add `.str` to the method chain.\n",
    "\n",
    "Here's a sample of Pandas string methods (you can see a full account in the [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#method-summary). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Pandas String Method** | **Explanation**                                                                                   |\n",
    "|:-------------:|:---------------------------------------------------------------------------------------------------:|\n",
    "| df['column_name']`.str.lower()`         | makes the string in each row lowercase                                                                                |\n",
    "| df['column_name']`.str.upper()`         | makes the string in each row uppercase                                                |\n",
    "| df['column_name']`.str.title()`         | makes the string in each row titlecase                                                |\n",
    "| df['column_name']`.str.replace('old string', 'new string')`      | replaces `old string` with `new string` for each row |\n",
    "| df['column_name']`.str.contains('some string')`      | tests whether string in each row contains \"some string\" |\n",
    "| df['column_name']`.str.split('delim')`          | returns a list of substrings separated by the given delimiter |\n",
    "| df['column_name']`.str.join(list)`         | opposite of split(), joins the elements in the given list together using the string                                                                        |\n",
    "                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform all the values in the \"MaterialType\" column to lower case, we can use `.str.lower()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['MaterialType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['MaterialType'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try to clean up some of the inconsistencies in our data by stripping trailing commas with `.str.strip(,)`.\n",
    "\n",
    "Here are the top 15 most frequent values in the \"Publisher\" column before we do any clean up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Publisher'].value_counts()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's strip commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Publisher'] = seattle_df['Publisher'].str.strip(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the top 15 most frequent values after our text manipulation. Looks a little better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Publisher'].value_counts()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `df.str.contains()` to search for whether a row contains a string, like *My Brilliant Friend*, even if it doesn't match the title exactly.\n",
    "\n",
    "If there are `NaN` values in a column, we can also choose to ignore them with `na = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean vector\n",
    "title_filter = seattle_df['Title'].str.contains('My Brilliant Friend', na=False)\n",
    "\n",
    "# Filter\n",
    "seattle_df[title_filter].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also test whether a row contains a certain word/phrase OR (`|`) other words/phrases. Additionally, we can choose to ignore case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean vector\n",
    "title_filter = seattle_df['Title'].str.contains('(my brilliant friend|story of a new name)',\n",
    "                                                na=False, case = False)\n",
    "\n",
    "# Filter\n",
    "seattle_df[title_filter]['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Regular Expression Pattern       | Matches |\n",
    "|:---------------------------:|:-----------------------------------------------------------------------------------------------------------:|\n",
    "| `.` | any character                                         | \n",
    "| `\\w` | word                                         | \n",
    "| `\\W`                      | NOT word                                           |  \n",
    "| `\\d` | digit                                         | \n",
    "| `\\D`                      | NOT digit                                           | \n",
    "| `\\s` | whitespace                                         | \n",
    "| `\\S`                      | NOT whitespace                                          | \n",
    "| `[abc]`                      | Any of abc                                         |\n",
    "| `[^abc]`                      | Not any of abc                                         | \n",
    "| `(abc)`                      | Specific capture of \"abc\"                                         \n",
    "| `+`                      | 1 or more instances                                       | \n",
    "| `*`                      | 0 or more instances                                         | \n",
    "| `?`                      | 0 or 1 instance                                        | \n",
    "| `{number}`                      | any specific number of instances                                        | \n",
    "\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use regular expressions with `.str.contains()`. For example, we could search for anything that has 4 numbers in a row `\\d{4}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean vector\n",
    "title_filter = seattle_df['Title'].str.contains('\\d{4}',\n",
    "                                                na=False, case = False, regex=True)\n",
    "\n",
    "# Filter\n",
    "seattle_df[title_filter]['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Pandas Method** | **Explanation**                                                                                   |\n",
    "|:-------------:|:---------------------------------------------------------------------------------------------------:|\n",
    "| df['column_name']`.apply(function_name)`         | Call function on every row in column                                                                                |\n",
    "| df`.apply(function_name, axis='columns')`         | Call function on every row in DataFrame                                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps we want to create a Python function that will clean up our data in a more nuanced and comprehensive way.\n",
    "\n",
    "For example, our \"PublicationYear\" column has a lot of irregularity. Many of the values are surrounded by square brackets`[]`, begin with the letter `c`, end with a period, or include multiple years (presumably a copyright year and a reissue year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['PublicationYear'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucky for us, Pandas makes it easy to apply functions to DataFrame and Series objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition pythonreview\" name=\"html-admonition\" style=\"background: lightgreen; padding: 10px\">\n",
    "<p class=\"title\"><b/>Python Review üêç </b></p>\n",
    "\n",
    "Python functions enable you to bundle up code and call that code whenever you need it. There are a number of built-in Python functions, such as:\n",
    "- `print()`\n",
    "- `len()`\n",
    "- `type()`\n",
    "\n",
    "To create a Python function of your own, you need to begin with the keyword `def`, short for define. Then you give the function a name followed by parenthesis, and often you specify an argument that it will accept inside the parenthesis, followed by a colon.\n",
    "\n",
    "```\n",
    "def clean_year(year):\n",
    "    year = year.replace('[', '')\n",
    "    year = year.replace(']', '')\n",
    "    return year\n",
    "\n",
    "clean_year(\"[2012]\")  \n",
    "\"2012\"  \n",
    "```\n",
    "\n",
    "Then you move to the next line, indent, and include the code that you want to be run when you \"call\" the function.\n",
    "\n",
    "Finally, you typically end with a `return` statement that will return a certain value(s).  \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a Python function on a DataFrame or Series object, you use `.apply()` and give the name of the desired function as an argument. This means the function will be called on every row in the DataFrame or every column.\n",
    "\n",
    "To make a useful Python function for your DataFrame/column, it can be useful to think about making a function that will work well on a single value, like \"c[2012]. \" or \"c2012 2020.  \" For these values, we want to remove characters like `[` or `c`, strip whitespace, and find a way to deal with multiple years. To make things simple, let's simply return \"Unknown\" if there is more than one year listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_year(year):\n",
    "    \n",
    "    # Convert number to string\n",
    "    year = str(year)\n",
    "    # Replace characters\n",
    "    year = year.replace('[', '')\n",
    "    year = year.replace(']', '')\n",
    "    year = year.replace('-', '')\n",
    "    year = year.replace(',', '')\n",
    "    year = year.replace('.', '')\n",
    "    year = year.replace('¬©', '')\n",
    "    year = year.replace('c', '')\n",
    "    year = year.replace('?', '')\n",
    "    # Strip whitespace\n",
    "    year = year.strip()\n",
    "    \n",
    "    # If there are more than 4 characters, return Unknown \n",
    "    if len(year) > 4:\n",
    "        year = 'Unknown'\n",
    "        \n",
    "    return year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out the function on single values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_year(\"c[2012].  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_year(\"c2012 2020.  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It works. Now let's apply the function to the entire column. Note that when we apply the function, we simply give the name and do not call it with parenthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['PublicationYear'].apply(clean_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we clean up the \"PublicationYear\" column, it looks a lot better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seattle_df['PublicationYear'] = seattle_df['PublicationYear'].apply(clean_year)\n",
    "\n",
    "seattle_df['PublicationYear'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that there are a lot of different variations of the titles, as well.\n",
    "\n",
    "Let's make a function that attempts to aggregate titles of the same name. Note that we're using more regular expressions here. Python functions allow you to get as fancy as you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_title(title):\n",
    "    \n",
    "    # Replace some words\n",
    "    title = title.lower().replace('(unabridged)', '')\n",
    "    title = title.lower().replace(': a novel', '')\n",
    "    \n",
    "    # Use regex expression to remove everything after / or :\n",
    "    # Test to see if there is a / character\n",
    "    if re.search('.+?(?=/)/', title):\n",
    "        # If so, pull out the text before the / character\n",
    "        title = re.search('.+?(?=/)/', title).group(0)\n",
    "    \n",
    "    # Test to see if there is a : character\n",
    "    if re.search('.+?(?=:)', title):\n",
    "        # If so, pull out the text before the / character\n",
    "        title = re.search('.+?(?=:)', title).group(0)\n",
    "    \n",
    "    # Strip character and whitespace\n",
    "    title = title.strip('/')\n",
    "    title = title.strip()\n",
    "    \n",
    "    title = title.title()\n",
    "    \n",
    "    return title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to run this cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Title'] = seattle_df['Title'].apply(clean_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: lightyellow; padding: 10px\">\n",
    "<p class=\"Question\"><b/>‚ùì Question</b></p>\n",
    "\n",
    "How dominant are the \"Big 5\" Publishers ‚Äî Penguin/Random House, Harper Collins, Hachette, Simon & Schuster, and Macmillan ‚Äî in the Seattle Public Library system?\n",
    "\n",
    "To answer this question, we need to `.apply()` a function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to get a sense of publishing trends in this dataset because there are a lot of different values for the same publisher ‚Äî not only slight differences like \"Random House, Inc.\" and \"Random House\" but bigger differences, too, like the fact that \"Viking\" is *owned* by Penguin/Random House.\n",
    "\n",
    "Can we account for these nuances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Publisher'].value_counts()[:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_5_checker(publisher):\n",
    "    \n",
    "    # Make lowercase to catch variations\n",
    "    publisher = publisher.lower()\n",
    "    \n",
    "    # Test to see if certain words are in the row, then return corresponding publisher\n",
    "    if \"random house\" in publisher or \"penguin\" in publisher or \"knopf\" in publisher or \"viking\" in publisher or \"ballantine\" in publisher:\n",
    "        return \"Penguin/Random House\"\n",
    "    elif \"harper\" in publisher:\n",
    "        return \"Harper Collins\"\n",
    "    elif \"simon\" in publisher:\n",
    "        return \"Simon & Schuster\"\n",
    "    elif \"hachette\" in publisher:\n",
    "        return \"Hachette\"\n",
    "    elif \"macmillan\" in publisher:\n",
    "            return \"Macmillan\"\n",
    "    else:\n",
    "        return \"Other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out the function on single values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_5_checker(\"Simon & Schuster - Audiobooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_5_checker(\"Viking,\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! It's working. Let's apply it to the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Big 5'] = seattle_df['Publisher'].apply(big_5_checker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh! We've gotten an error. The error reports that we can't use a string method, `.lower()`, on a `float` data type, which is likely a `NaN`.\n",
    "\n",
    "One way that we could handle this error is to simply drop `NaN` values before we apply the function with `.dropna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Big 5'] = seattle_df['Publisher'].dropna().apply(big_5_checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df[['Title', 'MaterialType', 'Checkouts', 'Publisher','Big 5']].sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Big 5'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: lightyellow; padding: 10px\">\n",
    "<p class=\"Question\"><b/>‚ùì Question</b></p>\n",
    "\n",
    "What are the most common \"Subjects\" in the Seattle Public Library circulation data between 2015-2021?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another lingering issue with this data is that the \"Subjects\" column contains a list of different subjects in each row, making it difficult to understand overall subject borrowing patterns.\n",
    "\n",
    "This is a tricky probelm and a case where we might want to call a Python function on the entire column, not just apply a function to each row of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Subjects'].value_counts()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a function that will accept an entire Pandas Series as an argument (\"Subjects\"), consider each row in the Series/column, split the row into a list based on comma separation, add each item to a list, and then make that list into its own Pandas Series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_upper_subjects(subjects_column):\n",
    "    \n",
    "    # Empty list\n",
    "    list_of_subjects = []\n",
    "    \n",
    "    # For each item's subjects in the entire column\n",
    "    for item_subjects in subjects_column:\n",
    "        \n",
    "        # Split on comma\n",
    "        item_subjects = item_subjects.split(',')\n",
    "        \n",
    "        for item_subject in item_subjects:\n",
    "\n",
    "            item_subject = item_subject.replace(',', '')\n",
    "            item_subject = item_subject.strip(',')\n",
    "            item_subject = item_subject.strip()\n",
    "\n",
    "            # Add to big list\n",
    "            list_of_subjects.append(item_subject)\n",
    "    \n",
    "    return pd.Series(list_of_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we call the function and give the \"Subjects\" column as an argument, we get a Series object of individual titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_upper_subjects(seattle_df['Subjects'].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And because it is a Series, we can use `.value_counts()` to count them all up. It seems to look ok, but..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_upper_subjects(seattle_df['Subjects'].dropna()).value_counts()[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...if we examine the last items in the Series, we can see that this method certainly isn't perfect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_upper_subjects(seattle_df['Subjects'].dropna()).value_counts()[-40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that some subjects in this dataset, like \"Women immigrants Australia Drama\", are NOT separated by commas. If we were really interested in this information, we would need to spend more time creating a function that could capture all the contingencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Pandas Data Convert Method** | **Explanation**                                                                                   |\n",
    "|:-------------:|:---------------------------------------------------------------------------------------------------:|\n",
    "| `df['column_name'].astype(str/int/float)`         | Convert column to a different data type                                                                                |\n",
    "| `pd.to_numeric(df['column_name'], errors='coerce')`         | Convert column to numerical data, with option to convert errors to `NaN`                                              |\n",
    "| `pd.to_datetime(df['column_name'], format='&Y-%M')`         | Convert column to datetime, specify date input format                                               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last section, we cleaned up a lot of our \"PublicationYear\" column. So now we should be able to filter the data and only look at works that were published in the 1970s...right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seventies_filter = (seattle_df['PublicationYear'] >= 1970) & (seattle_df['PublicationYear'] < 1980)\n",
    "\n",
    "seattle_df[seventies_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drat! We're getting an error message that says we can't use `>=` on a string object. If we remember, we do have string values in this column: \"Unknown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['PublicationYear']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to convert between Pandas data types is to use `.astype()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the column \"CheckoutYear\" is an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['CheckoutYear']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we wanted to make it an object instead, we could use `.astype()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['CheckoutYear'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's try it out on \"PublicationYear\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['PublicationYear'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double drat! We can't convert a `NaN` into an integer because it's a `float`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So instead we'll need to use a different way of converting to numeric data ‚Äî specficially, `pd.to_numeric()`, which includes an option for converting any problematic data into a `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(seattle_df['PublicationYear'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['PublicationYear'] = pd.to_numeric(seattle_df['PublicationYear'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seventies_filter = (seattle_df['PublicationYear'] >= 1970) & (seattle_df['PublicationYear'] < 1980)\n",
    "\n",
    "seattle_df[seventies_filter].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_filter = seattle_df['PublicationYear'].isna()\n",
    "\n",
    "seattle_df[null_filter].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Pandas Data Convert Method** | **Explanation**                                                                                   |\n",
    "|:-------------:|:---------------------------------------------------------------------------------------------------:|\n",
    "| `pd.to_datetime(df['column_name'], format='&Y-%M')`         | Convert column to datetime, specify date input format                                               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: lightyellow; padding: 10px\">\n",
    "<p class=\"Question\"><b/>‚ùì Question</b></p>\n",
    "\n",
    "How do Seattle Public Library checkouts between 2015-2021 fluctuate *month by month*?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last notebook, we were able to create a pretty basic plot of checkouts between 2015-2021 by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "materialtype_checkouts_byyear = seattle_df.groupby(['MaterialType', 'CheckoutYear'])\\\n",
    "                                [['Checkouts']].sum().reset_index()\n",
    "\n",
    "# Use Seaborn to make a line plot\n",
    "sns.lineplot(data=materialtype_checkouts_byyear,\n",
    "             x='CheckoutYear', y='Checkouts', hue='MaterialType')\n",
    "\n",
    "# Put legend to the right\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we couldn't get more granular than that, because we don't currently have a column with more granular date information.\n",
    "\n",
    "However, we do have a column with the check out year and the check out month, so let's try to combine that information together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df[['Title', 'Checkouts', 'CheckoutYear', 'CheckoutMonth']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One option for combining this data together is to simply concatenate the columns together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['CheckoutYear'] + seattle_df['CheckoutMonth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! Since these are integers, when we try to concatenate them together, we're just adding them together. To concatenate them, we need to convert them to string objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['CheckoutYear'].astype(str) + '-' + seattle_df['CheckoutMonth'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better! Let's make a new column with the check out year and month combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['CheckoutYearMonth'] = seattle_df['CheckoutYear'].astype(str) + '-' + seattle_df['CheckoutMonth'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explicitly make this column into datetime data, we need to use `pd.to_datetime(format=%Y-%m)` and specify the date format of our inputs (here are the [codes for datetime formatting](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(seattle_df['CheckoutYearMonth'], format='%Y-%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we specificed that this information was year and day `format=%Y-%d`, rather than month, then it would interpret the second numerical value as day information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(seattle_df['CheckoutYearMonth'], format='%Y-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Date'] = pd.to_datetime(seattle_df['CheckoutYearMonth'], format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition warning\" name=\"html-admonition\" style=\"background: pink; padding: 10px\">\n",
    "<p class=\"title\"><b/>Note</b></p>\n",
    "\n",
    "\n",
    "Note that if you have three columns in your DataFrame that have the titles \"year,\" \"month,\" and \"day,\" you can also make them a single datetime object in one fell swoop.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['CheckoutDay'] = 1\n",
    "seattle_df[['Year', 'Month', 'Day']] = seattle_df[['CheckoutYear','CheckoutMonth', 'CheckoutDay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(seattle_df[['Year', 'Month', 'Day']], format='%Y-%M-%D', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df = seattle_df.drop(['Year', 'Month', 'Day'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have actual datetime data, we can do more sophisticated time series analyses. For example, we can group by \"Date\" and calculate the total checkouts for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seattle_df.groupby('Date')['Checkouts'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df.groupby('Date')['Checkouts'].sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a lot more informative than year alone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df.groupby('CheckoutYear')['Checkouts'].sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same thing with our previous plot of material type checkouts over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "materialtype_checkouts_byyear = seattle_df.groupby(['MaterialType', 'Date'])\\\n",
    "                                            [['Checkouts']].sum().reset_index()\n",
    "\n",
    "top_material_filter = materialtype_checkouts_byyear['MaterialType']\\\n",
    "                        .isin(['BOOK', 'EBOOK', 'AUDIOBOOK', 'VIDEODISC'])\n",
    "\n",
    "# Use Seaborn to make a line plot\n",
    "sns.lineplot(data=materialtype_checkouts_byyear[top_material_filter],\n",
    "             x='Date', y='Checkouts', hue='MaterialType')\n",
    "\n",
    "# Put legend to the right\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datetime Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Pandas Datetime Index Methods** | **Explanation**                                                                                   |\n",
    "|:-------------:|:---------------------------------------------------------------------------------------------------:|\n",
    "| `df.resample('M')`         | Resample, or essentially group by, different spans of time, e.g., `Y`, `M`, `D`, `17min`                                                |\n",
    "| `df.loc['2018':'2019']`         | Index by label and slice DataFrame between the years 2018 and 2019                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common approach to working with time series infromation is to make the datetime column into our Pandas index. There are some special things we can do with a datetime index, such as slice the data by dates more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the \"Date\" column our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df = seattle_df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(seattle_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we can do with a Datetime Index is to `.resample()`, or essentailly group by, different time period spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df.resample('M')['Checkouts'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df.resample('Y')['Checkouts'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df.resample('Q')['Checkouts'].sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, because we can use `.loc` to index by date label, we can easily slice the DataFrame between 2019 and 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df.loc['2019':'2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df.loc['2019':'2020'].resample('M')['Checkouts'].sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could slice based on an even more granular dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df.loc['2020-04':'2020-10'].resample('M')['Checkouts'].sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting It All Together:\n",
    "## Plot Checkouts of Specific Titles and Creators Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_filter = seattle_df['Title'].str.contains('So You Want To Talk About Race', na=False, case=False)\n",
    "\n",
    "seattle_df[title_filter].resample('M')['Checkouts'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df[title_filter].loc['2019-10':'2021-01'].resample('M')['Checkouts'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkouts_byyear = seattle_df.groupby(['Title','Creator', 'Date', 'MaterialType'])[['Checkouts']].sum().reset_index()\n",
    "checkouts_byyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "creator_filter = checkouts_byyear['Creator'].str.contains('Ferrante')\n",
    "\n",
    "# Use Seaborn to make a line plot\n",
    "sns.lineplot(data= checkouts_byyear[creator_filter],\n",
    "             x='Date', y='Checkouts', hue='Title', lw=3, ci=None)\n",
    "\n",
    "# Put legend to the right\n",
    "plt.legend(bbox_to_anchor=(.3, .8),  loc='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the code with a Title or Creator of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_filter = seattle_df['Title'].str.contains('Title Of Your Choice', na=False, case=False)\n",
    "\n",
    "seattle_df[title_filter].resample('M')['Checkouts'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "creator_filter = checkouts_byyear['Creator'].str.contains('Creator of Your Choice',\n",
    "                                                          na=False, case=False)\n",
    "\n",
    "# Use Seaborn to make a line plot\n",
    "sns.lineplot(data= checkouts_byyear[creator_filter],\n",
    "             x='Date', y='Checkouts', hue='Title', lw=3, ci=None)\n",
    "\n",
    "# Put legend to the right\n",
    "plt.legend(bbox_to_anchor=(.3, .8),  loc='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're getting a lot of variations of titles, make sure you've applied the `clean_title()` function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_title(title):\n",
    "    \n",
    "    # Replace some words\n",
    "    title = title.lower().replace('(unabridged)', '')\n",
    "    title = title.lower().replace(': a novel', '')\n",
    "    \n",
    "    # Use regex expression to remove everything after / or :\n",
    "    # Test to see if there is a / character\n",
    "    if re.search('.+?(?=/)/', title):\n",
    "        # If so, pull out the text before the / character\n",
    "        title = re.search('.+?(?=/)/', title).group(0)\n",
    "    \n",
    "    # Test to see if there is a : character\n",
    "    if re.search('.+?(?=:)', title):\n",
    "        # If so, pull out the text before the / character\n",
    "        title = re.search('.+?(?=:)', title).group(0)\n",
    "    \n",
    "    # Strip character and whitespace\n",
    "    title = title.strip('/')\n",
    "    title = title.strip()\n",
    "    \n",
    "    title = title.title()\n",
    "    \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Title'] = seattle_df['Title'].apply(clean_title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
