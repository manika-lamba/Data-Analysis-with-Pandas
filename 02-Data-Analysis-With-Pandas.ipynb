{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with Pandas ‚Äî¬†Day 2\n",
    "## Sorting, Cleaning, Manipulation, Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Day 2 notebook for the June 2021 course \"Data Analysis with Pandas,\" part of the [Text Analysis Pedagogy Institute](https://nkelber.github.io/tapi2021/book/intro.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we will cover:\n",
    "\n",
    "* How to Make Simple Plots\n",
    "* How to Work with Missing Data\n",
    "* How to Rename, Drop, and Add New Columns\n",
    "* How to Sort Values\n",
    "* How to Group Values\n",
    "* How to Write to CSV\n",
    "\n",
    "___\n",
    "\n",
    "## Dataset\n",
    "### Seattle Public Library Book Circulation Data\n",
    "\n",
    "This week, we will be working with [circulation data](https://data.seattle.gov/Community/Checkouts-by-Title/tmmm-ytt6) made publicly avilable by the Seattle Public Library. The dataset includes items that were checked out 20+ times in a month between January 2015 and June 2021.\n",
    "\n",
    "For more information about this dataset, see the Seattle Public Library's [data portal](https://data.seattle.gov/Community/Checkouts-by-Title/tmmm-ytt6).\n",
    "___\n",
    "\n",
    "## Import Pandas\n",
    "\n",
    "To use the Pandas library, we first need to `import` it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Pandas will display 60 rows and 20 columns. I often change [Pandas' default display settings](https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html) to show more rows or columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read in a CSV file, we will use the function `pd.read_csv()` and insert the name of our desired file path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df = pd.read_csv('Seattle-Library_2015-2021.csv', delimiter=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make and Save Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas makes it easy to create simple plots and data visualizations.\n",
    "\n",
    "We can make a simple plot by adding `.plot()` to any DataFrame or Series object that has appropriate numeric data. If we use `.plot()` with a DataFrame, we need to specify an `x=` and `y=` axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['MaterialType'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can specify the title with the `title=` parameter and the kind of plot by altering the `kind=` parameter:\n",
    "* ‚Äòbar‚Äô or ‚Äòbarh‚Äô for bar plots\n",
    "\n",
    "* ‚Äòhist‚Äô for histogram\n",
    "\n",
    "* ‚Äòbox‚Äô for boxplot\n",
    "\n",
    "* ‚Äòkde‚Äô or ‚Äòdensity‚Äô for density plots\n",
    "\n",
    "* ‚Äòarea‚Äô for area plots\n",
    "\n",
    "* ‚Äòscatter‚Äô for scatter plots\n",
    "\n",
    "* ‚Äòhexbin‚Äô for hexagonal bin plots\n",
    "\n",
    "* ‚Äòpie‚Äô for pie plots   \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html) or the [Matplotlib documentation about `.plot()`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html) for more details about plotting options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition pythonreview\" name=\"html-admonition\" style=\"background: lightgreen; padding: 10px\">\n",
    "<p class=\"title\"><b/>Python Review üêç </b></p>\n",
    "\n",
    "Python `lists` consist of items separated by commas in square brackets.    \n",
    "\n",
    "--> `books = ['My Brilliant Friend', 'Goosebumps', 'Man in the High Castle', 'Thick']`  \n",
    "\n",
    "To slice a Python list and extract the first 2 values, we can use `[:2]`.e.g., `books[:2]`.  \n",
    "\n",
    "--> `['My Brilliant Friend', 'Goosebumps']`\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can slice our value counts with Python slicing and examine only the top 5 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['MaterialType'].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do the same thing with `.head(5)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['MaterialType'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a pie chart, we can set `kind='pie'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['MaterialType'].value_counts()[:5].plot(title='SPL Material Types 2015-2021',\n",
    "                                               kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save a plot as an image file or PDF file, we can assign the plot to a variable called `ax`, short for axes.\n",
    "\n",
    "Then we can use `ax.figure.savefig('FILE-NAME.extension')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = seattle_df['MaterialType'].value_counts()[:5].plot(kind='pie')\n",
    "# Save the figure as PDF\n",
    "ax.figure.savefig('SPL-MaterialTypes.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: skyblue; padding: 10px\">\n",
    "<p class=\"title\"><b/>Note</b></p>\n",
    "\n",
    "The special `NaN` value for missing data is a `float`.\n",
    "\n",
    "When `NaN`s appear in columns with text, the data type for the column is `object`, because the dtype `object` can be a mixture of text and numeric data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see if data is missing or NOT missing with `.isna()` or `.notna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Publisher'].isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check to see which rows do not have \"Publisher\" information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boolean vector -- create True/Falses\n",
    "publisher_null_checker = seattle_df['Publisher'].isna()\n",
    "# Filter\n",
    "seattle_df[publisher_null_checker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check to see which rows do not have \"Creator\" information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boolean vector -- create True/Falses\n",
    "creator_null_checker = seattle_df['Creator'].isna()\n",
    "# Filter\n",
    "seattle_df[creator_null_checker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check to see which rows do have \"Creator\" information with `.notna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boolean vector -- create True/Falses\n",
    "creator_notnull_checker = seattle_df['Creator'].notna()\n",
    "# Filter\n",
    "seattle_df[creator_notnull_checker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can \"fill\" all `NaN` values with `.fillna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Creator'].fillna('No Creator')[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop any row in the DataFrame that has any `NaN` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seattle_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can drop any row in the DataFrame that has an `NaN` value in a particular column(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seattle_df.dropna(subset=['Creator', 'Publisher'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revise a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run `.fillna()` on a column, we are not making permanent changes to that column or the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Creator'].fillna('No Creator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we look at this column, we can see that `NaN` values are still there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Creator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To revise a column or an entire DataFrame, we need to reassign the column to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Creator'] = seattle_df['Creator'].fillna('No Creator')\n",
    "seattle_df['Publisher'] = seattle_df['Publisher'].fillna('No Creator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the changes are permanent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Creator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rename a column with `.rename(columns={})` and include a `key:value` pair for `'original column':'renamed column'`.\n",
    "\n",
    "Again, changes will not be permanent unless we reassign the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seattle_df.rename(columns={'Creator': 'Author'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add an entirely new column to a DataFrame simply by assigning values to a new column name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Maker'] = seattle_df['Creator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seattle_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop a column by using `.drop()` and specifiying the name of the column and `axis=columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seattle_df = seattle_df.drop('Maker', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a DataFrame Copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we don't want to write over our DataFrame. Instead we want to make a new DataFrame.\n",
    "\n",
    "We can assign a DataFrame to a new variable with `df.copy()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we wanted to make a DataFrame `book_df` that only contains books, we could filter for only books, make a copy of this filtered DataFrame, and then reassign to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean vector\n",
    "book_filter = seattle_df['MaterialType'] == 'BOOK'\n",
    "\n",
    "# Create a copy of the filtered DataFrame and save as new DataFrame\n",
    "book_df = seattle_df[book_filter].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort a DataFrame by a particular column with `.sort_values()`.\n",
    "\n",
    "For a DataFrame, we also need to specify the column that we want to sort by (`by=`) and whether the sort order should be ascending (`ascending=True`) or False (`ascending=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seattle_df.sort_values(by='Checkouts', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort by multiple columns by putting them in square brackets as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seattle_df.sort_values(by=['CheckoutYear', 'Checkouts'], ascending=[False, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort a Series by simply using `.sort_values()`. Since there is only one column, we do not need to specify to sort `by=` a particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df['Checkouts'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: lightyellow; padding: 10px\">\n",
    "<p class=\"Question\"><b/>‚ùì Question</b></p>\n",
    "\n",
    "What is the total number of books checked out across the entire period 2015-2021?\n",
    "\n",
    "How does this number compare to the total number of ebooks, audiobooks, or videodiscs that were checked out?\n",
    "\n",
    "To answer these question, we can use `.groupby()`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `.groupby()`, we can split the DataFrame into groups, calculate statistics on those groups, and return collective results.\n",
    "\n",
    "For example, we can split the DataFrame into groups according to checkout material type, then calculate the sum total checkouts for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seattle_df.groupby('MaterialType')['Checkouts'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also split the DataFrame into groups according to checkout material type, then calculate the mean total checkouts for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "materialtype_groups = seattle_df.groupby('MaterialType')\n",
    "\n",
    "materialtype_groups['Checkouts'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add on `sort_values()` to sort the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "materialtype_groups['Checkouts'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: lightyellow; padding: 10px\">\n",
    "<p class=\"Question\"><b/>‚ùì Question</b></p>\n",
    "\n",
    "What are the most checked out *titles* across the entire period 2015-2021?\n",
    "\n",
    "To answer this question, we can again use `.groupby()`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `.groupby()`, we can split the DataFrame into groups, calculate statistics on those groups, and return collective results.\n",
    "\n",
    "For example, we can split the DataFrame into groups according to title, then calculate the sum total checkouts for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_groups = seattle_df.groupby('Title')\n",
    "\n",
    "title_groups[['Checkouts']].sum().sort_values(by='Checkouts', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even plot these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_df = seattle_df.groupby(['Title'])[['Checkouts']].sum()\\\n",
    "            .sort_values(by='Checkouts', ascending=False)[:10]\n",
    "\n",
    "top10_df.plot(kind='barh').invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can `.groupby()` multiple columns by putting the columns in square brackets as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleauthor_groups = seattle_df.groupby(['Title', 'Creator'])\n",
    "\n",
    "titleauthor_groups[['Checkouts']].sum().sort_values(by='Checkouts', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: lightyellow; padding: 10px\">\n",
    "<p class=\"Question\"><b/>‚ùì Question</b></p>\n",
    "\n",
    "What is the total number of books, ebooks, audiobooks checked out *per year* across the entire period 2015-2021? How do these rates fluctuate over time?\n",
    "\n",
    "To answer these question, we can use `.groupby()`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "materialtypeyear_groups = seattle_df.groupby(['MaterialType', 'CheckoutYear'])\n",
    "\n",
    "materialtypeyear_groups[['Checkouts']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "materialtypeyear_groups[['Checkouts']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot checkouts of the different material types over time. However, Pandas doesn't make it easy to distinguish between the material types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "materialtype_checkouts_byyear = materialtypeyear_groups[['Checkouts']].sum().reset_index()\n",
    "\n",
    "materialtype_checkouts_byyear.plot(x='CheckoutYear', y='Checkouts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we will be better served by incoroprating a different data viz library that handles coloring by category more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "materialtype_checkouts_byyear = seattle_df.groupby(['MaterialType', 'CheckoutYear'])\\\n",
    "                                [['Checkouts']].sum().reset_index()\n",
    "\n",
    "# Use Seaborn to make a line plot\n",
    "sns.lineplot(data=materialtype_checkouts_byyear,\n",
    "             x='CheckoutYear', y='Checkouts', hue='MaterialType')\n",
    "\n",
    "# Put legend to the right\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of types! Most of the types have few checkouts.\n",
    "\n",
    "If we wanted to focus on a few of the main material types, we could filter with `.isin()` before plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_material_filter = materialtype_checkouts_byyear['MaterialType']\\\n",
    "                        .isin(['BOOK', 'EBOOK', 'AUDIOBOOK', 'VIDEODISC'])\n",
    "\n",
    "# Use Seaborn to make a line plot\n",
    "sns.lineplot(data=materialtype_checkouts_byyear[top_material_filter],\n",
    "             x='CheckoutYear', y='Checkouts', hue='MaterialType')\n",
    "\n",
    "# Put legend to the right\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can output a DataFrame as a new CSV file with `.to_csv('filename.csv')`. If we don't want to include the index as a column, we can specify `index=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean vector\n",
    "book_filter = seattle_df['MaterialType'] == 'BOOK'\n",
    "\n",
    "# Create a copy of the filtered DataFrame and save as new DataFrame\n",
    "book_df = seattle_df[book_filter].copy()\n",
    "\n",
    "book_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the books DataFrame to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df.to_csv('SPL-Books.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can output an aggregated DataFrame of total checkouts per title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleauthor_groups = seattle_df.groupby(['Title', 'Creator'])\n",
    "\n",
    "titleauthor_groups[['Checkouts']].sum().sort_values(by='Checkouts', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_checkouts_per_title = titleauthor_groups[['Checkouts']]\\\n",
    "                            .sum().sort_values(by='Checkouts', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_checkouts_per_title.to_csv('Total-SPL-Checkouts_2015-2021.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
