{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with Pandas — Day 2 Workbook\n",
    "## Word Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Day 2 practice workbook for the June 2021 course \"Data Analysis with Pandas,\" part of the [Text Analysis Pedagogy Institute](https://nkelber.github.io/tapi2021/book/intro.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HathiTrust Extracted Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [HathiTrust Digital Library](https://www.hathitrust.org/) has released word frequencies per page for all 17 million books in its catalog. These word frequencies — plus part of speech tags and other information — are known as \"extracted features.\" \n",
    "\n",
    "The HTRC team has developed a Python package, the [HathiTrust Feature Reader](https://github.com/htrc/htrc-feature-reader), which allows you to access and work with the extracted features of books.\n",
    "\n",
    "Guess what: the HathiTrust Feature Reader relies heavily on Pandas! So we're going to practice our Pandas knowledge by applying the concepts to a new form of textual data. We're specifically going to examine Sandra Cisneros's coming-of-age novel *The House on Mango Street*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install HathiTrust Feature Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with HathiTrust's extracted features, we first need to install and import the [HathiTrust Feature Reader](https://github.com/htrc/htrc-feature-reader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install htrc-feature-reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htrc_features import Volume\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make DataFrame of Word Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get HathiTrust extracted features for a single volume, we can create a [Volume object](https://github.com/htrc/htrc-feature-reader#volume) with `Volume()` and the unique HathiTrust volume ID, then use the `.tokenlist()` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: skyblue; padding: 10px\">\n",
    "<p class=\"title\"><b/>How to Find a HathiTrust Volume ID</b></p>\n",
    "\n",
    "To locate the the HathiTrust volume ID for *The House on Mango Street*, we can search the HathiTrust catalog for this book and then click on \"Limited (search only),\" which will take us to the following web page: https://babel.hathitrust.org/cgi/pt?id=uc1.32106012740764.\n",
    "\n",
    "The HathiTrust Volume ID for *The House on Mango Street* is located after `id=` this URL: `uc1.32106012740764`. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Volume('uc1.32106012740764').tokenlist(case=False, drop_section=True).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DataFrame displays each page number, the words/tokens that appear on the page, the part-of-speech, and the number of times that the words/tokens appears on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mango_df = Volume('uc1.32106012740764').tokenlist(case=False, pos=True, drop_section=True).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine 10 Random Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examine 10 Random Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the DataFrame `mango_df` to only show words that are nouns or `NN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to only show words that are nouns or `NN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a New DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new DataFrame `pos_df` that only includes words that are nouns or `NN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new DataFrame `pos_df` that only includes words that are nouns or `NN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the DataFrame `pos_df` by word count from highest to lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame `pos_df` by word count from highest to lowest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the DataFrame `pos_df` by word count from highest to lowest, then examine first 30 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame `pos_df` by word count from highest to lowest, then examine first 30 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: lightyellow; padding: 10px\">\n",
    "<p class=\"Question\"><b/>❓ Question</b></p>\n",
    "\n",
    "What are the most frequent nouns in *The House on Mango Street* overall?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out, group by the word column \"lowercase\", then sum all the word counts per page. Finally, sort values from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the word column \"lowercase\", then sum all the word counts per page\n",
    "# Finally sort values from highest to lowest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now examine just the top 30 nouns overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the word column \"lowercase\", then sum all the word counts per page\n",
    "# Finally sort values from highest to lowest\n",
    "# Examine top 30 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Plot of Top Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the top 15 nouns as a new variable `top15_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the word column \"lowercase\", then sum all the word counts per page\n",
    "# Finally sort values from highest to lowest\n",
    "# Save top 15 values as top15_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then plot a bar chart of this smaller DataFrame `top15_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a bar chart of top15_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Chart Word(s) Frequency Across the Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot word frequency across the book by filtering by word. Try it out with other words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean vector\n",
    "word_filter = mango_df['lowercase'] == 'house'\n",
    "# Filter, then plot\n",
    "mango_df[word_filter].plot(x='page', y='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean vector\n",
    "word_filter = mango_df['lowercase'].isin(['mango', 'street'])\n",
    "# Filter, then plot\n",
    "mango_df[word_filter].plot(x='page', y='count')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
